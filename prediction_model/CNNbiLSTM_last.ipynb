{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D,Conv2D\n",
    "from keras.layers.convolutional import MaxPooling1D,MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import TimeDistributed, Dense, Flatten,ConvLSTM2D,RepeatVector\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "import tensorflow as tf \n",
    "from keras import backend as k \n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#from tensorflow.keras import Sequential\n",
    "#from tensorflow.keras.layers import Conv2D, Flatten, Dense, TimeDistributed, ConvLSTM2D, RepeatVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1=pd.read_csv('https://raw.githubusercontent.com/bre3760/ictbuilding/dev/data/anno1/eplusout/eplusout.csv')\n",
    "#df2=pd.read_csv('https://raw.githubusercontent.com/bre3760/ictbuilding/dev/data/anno2/eplusout/eplusout.csv')\n",
    "#df3=pd.read_csv('https://raw.githubusercontent.com/bre3760/ictbuilding/dev/data/anno3/eplusout/eplusout.csv')\n",
    "df1=pd.read_csv('/home/ict4bd/Anno1/eplusout.csv')\n",
    "df2=pd.read_csv('/home/ict4bd/Anno2/eplusout.csv')\n",
    "df3=pd.read_csv('/home/ict4bd/Anno3/eplusout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set number of timestep to use for prediction and to predict\n",
    "n_in = 12\n",
    "n_out = 6\n",
    "verbose=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changetime(df,year):\n",
    "    datetimeform = []\n",
    "    for i in range(len(df.index)):\n",
    "        tt = df[\"Date/Time\"][i]\n",
    "        days, hours = tt.split('  ')\n",
    "        tt = f'{days.split(\"/\")[1]}/{days.split(\"/\")[0]}/{year}{hours}'\n",
    "        tt = tt.replace(' ', '')\n",
    "        if '201724:' or '201824:' or '201924:' in tt:\n",
    "            tt=tt.replace('24:', '00:')\n",
    "            timestamp = time.mktime(datetime.strptime(tt, \"%d/%m/%Y%H:%M:%S\").timetuple())\n",
    "            timestamp += 86400\n",
    "            #timestamp = datetime.fromtimestamp(timestamp)\n",
    "\n",
    "        else:\n",
    "            timestamp = time.mktime(datetime.strptime(tt, \"%d/%m/%Y%H:%M:%S\").timetuple())\n",
    "            #timestamp = datetime.fromtimestamp(timestamp)\n",
    "        datetimeform.append(timestamp)\n",
    "\n",
    "    df[\"TimeStep\"]=datetimeform\n",
    "    \n",
    "changetime(df1,\"2017\")\n",
    "changetime(df2,\"2018\")\n",
    "changetime(df3,\"2019\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Extract mean temp time series\n",
    "#mean value of the 3 indoor zones\n",
    "def meanDF(df):\n",
    "    df_mean = pd.DataFrame()\n",
    "    #\"Date/Time\",\\\n",
    "    #\"Environment:Site Outdoor Air Drybulb Temperature [C](TimeStep)\",\\\n",
    "    #\"Electricity:Facility [J](TimeStep)\"\n",
    "    df_mean = df[[\n",
    "              \"BLOCK1:BEDROOM:Zone Mean Air Temperature [C](TimeStep:ON)\",\\\n",
    "              \"BLOCK1:BATHROOM:Zone Mean Air Temperature [C](TimeStep:ON)\",\\\n",
    "              \"BLOCK1:KITCHEN:Zone Mean Air Temperature [C](TimeStep:ON)\",\\\n",
    "              ]]\n",
    "    df_temp=df_mean.copy()\n",
    "    df_temp.dropna(inplace=True)\n",
    "    df_temp[\"mean\"] = df_temp.mean(1)\n",
    "\n",
    "\n",
    "    df_final=pd.DataFrame()\n",
    "    df_final[\"DateTime\"] = df[\"TimeStep\"]\n",
    "    df_final[\"Outdoor_Mean\"] = df[\"Environment:Site Outdoor Air Drybulb Temperature [C](TimeStep)\"]\n",
    "    df_final[\"Indoor_Mean\"] = df_temp[\"mean\"]\n",
    "    df_final[\"Cooling\"] = df[\"DistrictCooling:Facility [J](TimeStep)\"]\n",
    "    df_final[\"Power\"]=df[\"Electricity:Facility [J](TimeStep)\"]\n",
    "    df_final[\"Delta_T\"] = df_final[\"Indoor_Mean\"]-df_final[\"Outdoor_Mean\"]\n",
    "    \n",
    "    #df_final\n",
    "    return df_final\n",
    "\n",
    "df1_final=meanDF(df1)\n",
    "df2_final=meanDF(df2)\n",
    "df3_final=meanDF(df3)\n",
    "df1_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only the values to train the rnn on \n",
    "x = pd.DataFrame()\n",
    "meas = [\n",
    "        #\"TimeStep\",\n",
    "        \"DistrictCooling:Facility [J](TimeStep)\",\n",
    "        \"Electricity:Facility [J](TimeStep)\",\n",
    "        \"Environment:Site Outdoor Air Drybulb Temperature [C](TimeStep)\",\n",
    "        \"Environment:Site Direct Solar Radiation Rate per Area [W/m2](TimeStep)\",\n",
    "        \"Environment:Site Wind Speed [m/s](TimeStep)\",\n",
    "        \"Environment:Site Outdoor Air Barometric Pressure [Pa](TimeStep)\",\n",
    "        \"Environment:Site Wind Direction [deg](TimeStep)\",\n",
    "        \"Environment:Site Diffuse Solar Radiation Rate per Area [W/m2](TimeStep)\",\n",
    "        \"BLOCK1:BEDROOM:Zone Mean Air Temperature [C](TimeStep:ON)\",\n",
    "        \"BLOCK1:BATHROOM:Zone Mean Air Temperature [C](TimeStep:ON)\",\n",
    "        \"BLOCK1:KITCHEN:Zone Mean Air Temperature [C](TimeStep:ON)\"]\n",
    "\n",
    "#x[\"Indoor_Mean\"] = pd.concat([df1_final[\"Indoor_Mean\"],df2_final[\"Indoor_Mean\"],df3_final[\"Indoor_Mean\"]])\n",
    "\n",
    "for m in meas:\n",
    "    x[m]=pd.concat([df1[m],df2[m],df3[m]])\n",
    "#x.set_index(\"TimeStep\",inplace=True)\n",
    "#x.head()\n",
    "x.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_indices = {name: i for i, name in enumerate(x.columns)}\n",
    "x.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\t\"\"\"\n",
    "\tFrame a time series as a supervised learning dataset.\n",
    "\tArguments:\n",
    "\t\tdata: Sequence of observations as a list or NumPy array.\n",
    "\t\tn_in: Number of lag observations as input (X).\n",
    "\t\tn_out: Number of observations as output (y).\n",
    "\t\tdropnan: Boolean whether or not to drop rows with NaN values.\n",
    "\tReturns:\n",
    "\t\tPandas DataFrame of series framed for supervised learning.\n",
    "\t\"\"\"\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed = series_to_supervised(x.to_numpy(), n_in, n_out)\n",
    "if verbose:\n",
    "    reframed.head()\n",
    "#reframed.shape\n",
    "\n",
    "#range(x.shape[1]*n_in+1,x.shape[1]*n_in+x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[]\n",
    "for i in range(n_out):\n",
    "    for c in reframed.columns[range(x.shape[1]*n_in+1+i*x.shape[1],x.shape[1]*n_in+ (i+1)*x.shape[1])]:\n",
    "        columns.append(c)\n",
    "if verbose:\n",
    "    print(columns)\n",
    "reframed.drop(columns, axis=1, inplace=True)\n",
    "reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_in = 6\n",
    "#n_out = 2\n",
    "#reframed = series_to_supervised(x.to_numpy(), n_in, n_out)\n",
    "#reframed.drop(reframed.columns[range(x.shape[1]*n_in+1,x.shape[1]*n_in+x.shape[1])], axis=1, inplace=True)\n",
    "#reframed.head()\n",
    "#reframed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train, validation and test and normalize data\n",
    "\n",
    "ntot = reframed.shape[0]\n",
    "values = reframed.values\n",
    "\n",
    "#first two years for training \n",
    "x_train = values[:(len(df1)+len(df2)), :]\n",
    "#x_train.set_index(\"TimeStep\",inplace=True)\n",
    "mean = x_train.mean()\n",
    "std = x_train.std()\n",
    "x_train_norm = (x_train - mean)/std\n",
    "print(\"Training set dimension: \",len(x_train))\n",
    "\n",
    "x_val =  values[(len(df1)+len(df2)): (len(df1)+len(df2)) + int(0.5*len(df3)), :]\n",
    "#x_val.set_index(\"TimeStep\",inplace=True)\n",
    "x_val_norm = (x_val-mean)/std\n",
    "print(\"Validation set dimension: \",len(x_val))\n",
    "\n",
    "x_test =  values[(len(df1)+len(df2)) + int(0.5*len(df3)):, :]\n",
    "#x_test.set_index(\"TimeStep\",inplace=True)\n",
    "x_test_norm = (x_test-mean)/std\n",
    "print(\"Test set dimension: \",len(x_test))\n",
    "\n",
    "train_X, train_y = x_train_norm[:, :-n_out],  x_train_norm[:, -n_out:]\n",
    "val_X, val_y = x_val_norm[:, :-n_out],  x_val_norm[:, -n_out:]\n",
    "test_X, test_y = x_test_norm[:, :-n_out],  x_test_norm[:, -n_out:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_lstm_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(TimeDistributed(Conv1D(filters=64, kernel_size=2, activation='relu'), input_shape=(None, n_steps, n_features)))\n",
    "\tmodel.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "\tmodel.add(TimeDistributed(Conv1D(filters=64, kernel_size=2,activation='relu')))\n",
    "\tmodel.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "\tmodel.add(TimeDistributed(Flatten()))\n",
    "\tmodel.add(Bidirectional(LSTM(64, activation='relu',return_sequences=True)))\n",
    "\tmodel.add(Bidirectional(LSTM(64, activation='relu')))\n",
    "\tmodel.add(Dense(128))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(n_out))\n",
    "\tmodel.compile(optimizer='adam', loss='mse',metrics = ['mae','mse','mape'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN-Bi-LSTM \n",
    "#n_steps, n_features = train_X.shape[1], train_X.shape[2]\n",
    "n_features = 1 #da predirre\n",
    "n_seq = 1\n",
    "n_steps = 11*(n_in)\n",
    "\n",
    "train_X = train_X.reshape((train_X.shape[0], n_seq, n_steps, n_features))\n",
    "val_X = val_X.reshape((val_X.shape[0], n_seq, n_steps, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_seq, n_steps, n_features))\n",
    "\n",
    "#Define Model\n",
    "model = bi_lstm_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_X, train_y, epochs=100, batch_size=30, validation_data=(val_X, val_y), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_denorm = [t*std+mean for t in yhat]\n",
    "pred_df = pd.DataFrame(pred_denorm)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_denorm = [t*std+mean for t in test_y]\n",
    "test = pd.DataFrame(test_denorm)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_out):\n",
    "    \n",
    "    plt.figure(figsize=(20,20))\n",
    "#plot_test.reset_index(inplace=True,drop=True)\n",
    "    plt.plot(test[1][5025:7000],label='x_test_'+str((i+1)*10))\n",
    "    plt.plot(pred_df[1][5025:7000],label='predicted_'+str((i+1)*10))\n",
    "    plt.legend()\n",
    "    plt.title(\"DistrictCooling Facility Prediction at min: \"+ str((i+1)*10))\n",
    "    plt.savefig('min'+ str((i+1)*10)+'.png')\n",
    "#print(plot_test[4:])\n",
    "#print(pred_df[0:8])\n",
    "#plot_test.reset_index(inplace=True,drop=True)\n",
    "#print(plot_t.shape)\n",
    "#print(pred_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true+1))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err=np.abs(pred_df-test)/(test+1)\n",
    "err={}\n",
    "for i in range(n_out):\n",
    "    err[i]=[]\n",
    "for i in range(len(test)):\n",
    "    for r in range(n_out):\n",
    "        if test[r][i]!=0:\n",
    "            err[r].append(np.abs(pred_df[r][i]-test[r][i])/(test[r][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot mean absolute percentage errore\n",
    "mean=[]\n",
    "for k in err.keys():\n",
    "    mean.append(np.mean(err[k]))\n",
    "plt.plot([v *100 for v in mean])\n",
    "plt.title(\"MAPE for different horizon of prediction\")\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.savwfig('MAPEhorizon.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[m*100 for m in mean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(inv_y,inv_yhat):\n",
    "\t# calculate metrics\n",
    "\trmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "\tmse = mean_squared_error(inv_y, inv_yhat)\n",
    "\tmae = mean_absolute_error(inv_y, inv_yhat)\n",
    "\tmape = mean_absolute_percentage_error(inv_y, inv_yhat)\n",
    "\treturn rmse, mse, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse, mse, mae, mape = calculate_metrics(test, pred_df)\n",
    "\n",
    "print(\"Test MSE: %.3f\"%mse)\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "print(\"Test MAE: %.3f\" % mae)\n",
    "#print(\"Test MAPE: %.3f\" % mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 'neurons': 12\n",
    "\n",
    "# Total window size: 8 -> Input indices: [0 1 2 3 4 5] Label indices: [6 7]\n",
    "# loss: 0.0151 - mean_absolute_percentage_error: 36.4191 - rmse: 89737.6441121866\n",
    "\n",
    "# Total window size: 12 -> Input indices: [0 1 2 3 4 5] Label indices: [ 6  7  8  9 10 11]\n",
    "# loss: 0.0378 - mean_absolute_percentage_error: 75.3893 - rmse: 165518.73420347186\n",
    "\n",
    "# Total window size: 16 -> Input indices: [0 1 2 3 4 5 6 7 8 9] Label indices: [10 11 12 13 14 15]\n",
    "# loss: 0.0358 - mean_absolute_percentage_error: 58.4344 - rmse: 168050.95017360165\n",
    "\n",
    "# Total window size: 16 -> Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11] Label indices: [12 13 14 15]\n",
    "# loss: 0.0278 - mean_absolute_percentage_error: 71.6392 - rmse: 140321.72971796765\n",
    "\n",
    "# Total window size: 18 -> Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11] Label indices: [12 13 14 15 16 17]\n",
    "# loss: 0.0356 - mean_absolute_percentage_error: 84.7530 - rmse: 176186.70476650228\n",
    "\n",
    "\n",
    "## \n",
    "\n",
    "# Total window size: 216 (144 inputs, 72 outputs)\n",
    "# \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
